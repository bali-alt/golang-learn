## 并发介绍

### 进程和线程

```
1.进程是程序在操作系统中的一次执行过程，系统进行资源分配和调度的一个独立单位
2.线程是进程的一个执行实体，是CPU调度和分派的基本单位，它是比进程更小的能独立运行的基本单位
3.一个进程可以创建和撤销多个进程，同一个进程中多个线程可以并发执行
```

### 并发和并行

```
1.多线程程序在一个核的CPU上运行，就是并发
2.多线程程序在多个核的CPU上运行，就是并行
```

#### 并发

![image-20220219120237484](assets/image-20220219120237484.png)

#### 并行

![image-20220219120255846](assets/image-20220219120255846.png)

### 协程和线程

```
协程：独立的栈空间，共享堆空间，调用由用户自己控制，本质上优点类似于用户级线程，这些用户用户级线程的调度也是自己实现
线程：一个线程上可以跑多个协程，协程是轻量级的线程
```

### goroutine只是由官方实现的超级线程池

```
每个实例拥有 4-5k 的栈内存占用和由于实现机制而大幅减少的创建和销毁开销是go高并发的根本原因
```

### 并发不是并行

```
并发主要由切换时间片来实现”同时”运行，并行则是直接利用多核实现多线程的运行，go可以设置使用核数，以发挥多核计算机的能力
```

## goroutine 

> goroutine奉行通过通信来共享内存，而不是共享内存来通信

```
调用函数的时候在前面加上go关键字，就可以位一个函数创建一个goroutine
```

### 启动单个goroutine 

```
	只需要在调用的函数前面加上一个go关键字
```

### 启动多个goroutine 

```go
var wg sync.WaitGroup

func hello(i int) {
    defer wg.Done() // goroutine结束就登记-1
    fmt.Println("Hello Goroutine!", i)
}
func main() {

    for i := 0; i < 10; i++ {
        wg.Add(1) // 启动一个goroutine就登记+1
        go hello(i)
    }
    wg.Wait() // 等待所有登记的goroutine都结束
}
// 主协程退出，其他的任务不会继续执行
```

### goroutine 和线程

#### 可增长的栈

```
	OS线程一般都有固定的栈大小，一个goroutine的栈在其生命周期开始时只有很小的栈，可以按需增大和缩小
```

#### goroutine 调度

```
GPM是go语言运行时层面的实现，是go语言自己实现的一套调度系统。
1.G是一个goroutine，里面除了存放goroutine信息外，还有与所在P的绑定等信息
2.P管理着一组goroutine队列，P里面会存放着当前goroutine运行的上下文环境，P会对自己管理的goroutine队列做一些调度，当自己的队列消费完成后就去其他队列P的队列里抢任务，如果没有则去全局队列拿任务
3.M是Go运行时对操作系统内核线程的虚拟，M约内核线程一般是一对一的映射关系，一个goroutine最后要放到m上执行
```

## runtime包

### runtime.Gosched()

> 让出当前的CPU时间片，重新安排任务执行

### runtime.Goexit()

> 退出当前协程

### runtime.GOMAXPROCS()

> go运行时的调度器使用GOMAXPROCS参数来确定需要使用多少OS线程同时执行Go代码，默认是机器上的CPU核心数。

## channel

​	go语言的并发模型是CSP，提倡通过通信共享内存而不是用过共享内存实现通信。

​	channel是一种特殊的类型，就像一个队列，准讯先进先出规则，保证收发数据的顺序。

### channel类型

```
channel是一种类型，引用类型

var 变量 chan 元素类型
```

### 创建channel

```
通道是引用类型，通道类型的空值是nil
使用make进行初始化

ch := make(chan int)
```

### channel操作

```
通道由发送、接收和关闭三种操作
发送和接收都用<-符号

ch := make(chan int)
// 发送
ch <- 10
// 接收
x := <- ch
<- ch // 忽略值
// 关闭
cloese(ch)

关闭后的通道的特点：
1.对一个关闭的通道再发值会导致panic
2.对一个关闭的通道接收会一直获取到取值知道通道位为空
3.对一个关闭的并且没有值的通道执行接收操作会得到对应类型的零值
4.关闭一个已经关闭的通道会panic
```

### 无缓冲的通道

```
无缓冲的通道又称为阻塞的通道，

func main() {
    ch := make(chan int)
    ch <- 10
    fmt.Println("发送成功")
}   
// 会出现deadlock
```

### 有缓冲的通道

```
使用make函数初始化的通道的时候为其制定通道的容量

func main() {
	ch := make(chan int, 1)
	ch <- 10
	fmt.Println("发送成功")
}

len()
cap()
```

### close()

```
使用内置的close()函数关闭channel
```

### 单向通道

```
1.chan<- int是只发送
2.<-chan int是只接收
```

## goroutine池

```
wooker pool 
1.本质上是生产者消费者模型
2.可以有效控制goroutine树立那个，防止暴涨
```

## 定时器

### Timer

> 时间到了，执行一次

```
timer := time.NewTimer(time.Second)

// 等待
<-timer.C
// 停止
timer.Stop()
// 重置
timer.Reset(time.Second)

// 等待
time.After(time.Second)
```

### Ticker

> 时间到了，执行数次

```
ticker := time.NewTicker(time.Second * 2)
<-ticker.C
```

## select

```
select类似switch语句，它有一系列的case分支和一个默认的分支，每个case会对应一个通道的通信过程，select会一直等待知道某个case的通信操作完成，就会执行case分支对应的语句

select {
	case <-chan1:
	case chan2<-1:
	default:
}
```

## 并发安全和锁

> 有时候Go代码中可能存在多个goroutine同时操作一个资源（临界区），这种情况会发生竟态问题

### 互斥锁

```
互斥锁是一种常用的控制共享资源访问的方法，它能保证只有一个goroutine可以访问资源，使用sync包下的mutex实现

使用互斥锁能够保证同一时间有且只有一个goroutine进入临界区，其他的goroutine则在等待锁；当互斥锁释放后，等待的goroutine才可以获取锁进入临界区，多个goroutine同时等待一个锁时，唤醒的策略是随机的
```

### 读写互斥锁

```
	读锁：当一个goroutine获取读锁之后，其他的goroutine如果是获取读锁会继续获得锁，如果是获取写锁就会等待

	写锁：当一个goroutine获取写锁之后，其他的goroutine无论是获取读锁还是写锁都会等待
```

## sync

### sync.WaitGroup

| 方法名                         | 功能                |
| ------------------------------ | ------------------- |
| (wg *WaitGroup) Add(delta int) | 计数器+delta        |
| (wg *WaitGroup) Done()         | 计数器-1            |
| (wg *WaitGroup) Wait()         | 阻塞直到计数器变成0 |

​	sync.WaitGroup内部维护着一个计数器，计数器的值可以增加和减少。sync.WaitGroup是一个结构体，传递时要用指针。

### sync.Once

​	某些操作在高并发场景下，某些操作只需要执行一次，如加载配置文件，关闭通道

​	sync.Once只有一个Do方法，其签名:

```
func (o *Once) Do(f func()) {}
```

​	sync.Once其实内部包含一个互斥锁和一个布尔值，互斥锁保证布尔值和数据的安全，而布尔值用来记录初始化是否完成。这样设计就能保证操作的时候是并发安全的并且初始化操作也不会多次执行

### sync.Map

​	内置的map不是并发安全的，sync包提供了一个并发安全的sync.Map，开箱即用不用使用make函数初始化，同时内置了Store, Load, LoadOrStore, Delete, Range等操作

```go
var m = sync.Map{}

func main() {
    wg := sync.WaitGroup{}
    for i := 0; i < 20; i++ {
        wg.Add(1)
        go func(n int) {
            key := strconv.Itoa(n)
            m.Store(key, n)
            value, _ := m.Load(key)
            fmt.Printf("k=:%v,v:=%v\n", key, value)
            wg.Done()
        }(i)
    }
    wg.Wait()
} 
```

## 原子操作（atomic包）

​	加锁操作涉及到内核态的上下文切换会比较耗时，代价比较高。针对基本数据类型可以使用院子操作保证并发安全，性能比加锁更好。

| 方法           | 解释     |
| -------------- | -------- |
| Load           | 读取     |
| Store          | 写入     |
| Add            | 修改     |
| Swap           | 交换     |
| CompareAndSwap | 比较交换 |

## GMP原理

### 旧版调度器缺点

```
1.创建、销毁、调度G都需要每个M获得锁，形成了锁竞争
2.M转移G会造成延迟和额外的系统负载
3.系统调用导致频繁的线程阻塞和取消阻塞操作增加了系统开销
```

### GMP模型

- 全局队列（Global Queue）：存放等待运行的 G。
- P 的本地队列：同全局队列类似，存放的也是等待运行的 G，存的数量有限，不超过 256 个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。
- P 列表：所有的 P 都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个。
- M：线程想运行任务就得获取 P，从 P 的本地队列获取 G，P 队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。

​	Goroutine调度器和OS调度器通过M结合起来，每个M代表一个内核线程那个，OS调度器负责吧内核线程分配到CPU执行

1. P的数量由$GOMAXPROCS或者由runtime的GOMAXPROCS()决定
2. M的数量
   - go启动时设置默认M最大值为10000
   - runtime.debug中的SetMAXThreads函数设置M的最大值
   - 一个M阻塞了会创建新的M

### 调度器的设计策略

1. 复用线程：避免频繁的创建、销毁线程，对线程做复用
2. work stealing机制：本线程无可运行的G时，尝试从其他线程绑定的P偷取G，而不是销毁线程
3. hand off机制：当本地线程因为G进行系统调用阻塞时，线程释放绑定的P，把P转移给其他空闲的线程执行
4. 利用并行：GOMAXPROCS设置P的数量，最多有GOMAXPROCS个线程分布在多个CPU上同时运行，GOMAXPROCS也限制了并发的程度，比如GOMAXPROCS=核数/2，则最多利用了一半的CPU核进行并行
5. 抢占：在coroutine中腰等待一个协程主动让出CPU才执行下一个协程，在GO中，一个goroutine最多占用CPU10ms，防止其他goroutine被饿死
6. 全局 G 队列：在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G

![image-20220220120030390](assets/image-20220220120030390.png)

### 可视化GMP

1. go tool trace

```go
func main() {

    //创建trace文件
    f, err := os.Create("trace.out")
    if err != nil {
        panic(err)
    }

    defer f.Close()

    //启动trace goroutine
    err = trace.Start(f)
    if err != nil {
        panic(err)
    }
    defer trace.Stop()

    //main
    fmt.Println("Hello World")
}
```

```
go tool trace trace.out 
```

2. debug trace

```
go build main.go
GODEBUG=schedtrace=1000 ./main
```

```
SCHED 0ms: gomaxprocs=10 idleprocs=7 threads=4 spinningthreads=1 idlethreads=0 runqueue=0 [1 0 0 0 0 0 0 0 0 0]
Hello World
SCHED 1006ms: gomaxprocs=10 idleprocs=10 threads=5 spinningthreads=0 idlethreads=3 runqueue=0 [0 0 0 0 0 0 0 0 0 0]
Hello World
SCHED 2012ms: gomaxprocs=10 idleprocs=10 threads=5 spinningthreads=0 idlethreads=3 runqueue=0 [0 0 0 0 0 0 0 0 0 0]
Hello World
SCHED 3021ms: gomaxprocs=10 idleprocs=10 threads=5 spinningthreads=0 idlethreads=3 runqueue=0 [0 0 0 0 0 0 0 0 0 0]
Hello World
SCHED 4031ms: gomaxprocs=10 idleprocs=10 threads=5 spinningthreads=0 idlethreads=3 runqueue=0 [0 0 0 0 0 0 0 0 0 0]
Hello World

```



- `SCHED`：调试信息输出标志字符串，代表本行是 goroutine 调度器的输出；
- `0ms`：即从程序启动到输出这行日志的时间；
- `gomaxprocs`: P 的数量，默认的 P 的属性是和 cpu 核心数量默认一致，当然也可以通过 GOMAXPROCS 来设置；
- `idleprocs`: 处于 idle 状态的 P 的数量；通过 gomaxprocs 和 idleprocs 的差值，我们就可知道执行 go 代码的 P 的数量；
- `threads`: os threads/M 的数量，包含 scheduler 使用的 m 数量，加上 runtime 自用的类似 sysmon 这样的 thread 的数量；
- `spinningthreads`: 处于自旋状态的 os thread 数量；
- `idlethread`: 处于 idle 状态的 os thread 的数量；
- `runqueue=0`： Scheduler 全局队列中 G 的数量；
- `[0 0 0 0 0 0 0 0 0 0]`: 分别为 10 个 P 的 local queue 中的 G 的数量。
